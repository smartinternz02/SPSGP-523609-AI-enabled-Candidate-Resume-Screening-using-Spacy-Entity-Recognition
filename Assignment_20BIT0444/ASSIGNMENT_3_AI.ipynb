{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54790,"status":"ok","timestamp":1688366813686,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"},"user_tz":-345},"id":"l6ncjeX5RDPz","outputId":"f3645b28-0d9e-4a19-df65-1705860fc8ac"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["#Assignment 3\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4511,"status":"ok","timestamp":1688366818187,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"},"user_tz":-345},"id":"Iv61dqyb9cox","outputId":"aef57eb5-5bae-4199-db57-1b500e0c834f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GI37LuVGTb7L","executionInfo":{"status":"ok","timestamp":1688366820643,"user_tz":-345,"elapsed":2463,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"}}},"outputs":[],"source":["\n","from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8657,"status":"ok","timestamp":1688366829294,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"},"user_tz":-345},"id":"_9vO1V44UdR1","outputId":"d7e68259-18c0-4fc7-d2f0-9f3897caf757"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 150 images belonging to 1 classes.\n","Found 157 images belonging to 1 classes.\n"]}],"source":["\n","\n","train_gen = ImageDataGenerator(\n","    rescale=1./255,\n","    horizontal_flip=True,\n","    shear_range=0.2,\n","    zoom_range=0.2\n",")\n","test_gen = ImageDataGenerator(rescale=1./255)\n","train = train_gen.flow_from_directory(\n","    '/content/drive/MyDrive/AI_SmartInternz/archive/train_data',\n","    target_size=(120, 120),\n","    class_mode='categorical',\n","    batch_size=8\n",")\n","\n","test = test_gen.flow_from_directory(\n","    '/content/drive/MyDrive/AI_SmartInternz/archive/test_data',\n","    target_size=(120, 120),\n","    class_mode='categorical',\n","    batch_size=8\n",")\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1688366829295,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"},"user_tz":-345},"id":"3a9L20WsUvel","outputId":"8ea24448-170f-4896-e70a-55d224020ee9"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'train_data': 0}\n","{0: 'train_data'}\n","Key 2 does not exist in the dictionary.\n"]}],"source":["train.class_indices\n","index_var = train.class_indices\n","\n","# Create a new dictionary with keys and values swapped\n","new_index_var = {value: key for key, value in index_var.items()}\n","print(index_var)\n","print(new_index_var)\n","\n","key_to_find = 2\n","\n","if key_to_find in new_index_var:\n","    value = new_index_var[key_to_find]\n","    print(f\"The value corresponding to key {key_to_find} is: {value}\")\n","else:\n","    print(f\"Key {key_to_find} does not exist in the dictionary.\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Lk88pk8_UvhM","executionInfo":{"status":"ok","timestamp":1688366832849,"user_tz":-345,"elapsed":3588,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","model = Sequential()\n","model.add(Convolution2D(12,(3,3),activation='relu',input_shape=(120, 120,3))) #input_dim is target size and 3(channel) is rgb color img, for black n white 1\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(24,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Convolution2D(36,(3,3),activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Flatten())\n","model.add(Dense(128,activation='relu'))\n","model.add(Dense(62,activation='relu'))\n","model.add(Dense(32,activation='relu'))\n","model.add(Dense(16,activation='softmax')) # 16 coz the train,test have 16 folders\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1688366832851,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"},"user_tz":-345},"id":"wKjl9z2SUvkB","outputId":"2c99c4ff-6916-462e-a4d5-ce3e914612a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 118, 118, 12)      336       \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 59, 59, 12)       0         \n"," )                                                               \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 57, 57, 24)        2616      \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 28, 28, 24)       0         \n"," 2D)                                                             \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 26, 26, 36)        7812      \n","                                                                 \n"," max_pooling2d_2 (MaxPooling  (None, 13, 13, 36)       0         \n"," 2D)                                                             \n","                                                                 \n"," flatten (Flatten)           (None, 6084)              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               778880    \n","                                                                 \n"," dense_1 (Dense)             (None, 62)                7998      \n","                                                                 \n"," dense_2 (Dense)             (None, 32)                2016      \n","                                                                 \n"," dense_3 (Dense)             (None, 16)                528       \n","                                                                 \n","=================================================================\n","Total params: 800,186\n","Trainable params: 800,186\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model.summary()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"3Aj5LBzcZ3pL","executionInfo":{"status":"ok","timestamp":1688366832855,"user_tz":-345,"elapsed":16,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"}}},"outputs":[],"source":["model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WqgiTSMpaYCq","outputId":"dd0e48ed-0790-4439-f34f-6fa0cf8d6ac7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","19/19 [==============================] - 274s 15s/step - loss: 25920.5137 - accuracy: 0.0000e+00 - val_loss: 7285.1777 - val_accuracy: 0.0446\n","Epoch 2/50\n","19/19 [==============================] - 88s 5s/step - loss: 607283.9375 - accuracy: 0.0000e+00 - val_loss: 128188.5078 - val_accuracy: 0.0446\n","Epoch 3/50\n","19/19 [==============================] - 88s 5s/step - loss: 6739995.0000 - accuracy: 0.0000e+00 - val_loss: 1190566.6250 - val_accuracy: 0.0446\n","Epoch 4/50\n","19/19 [==============================] - 87s 5s/step - loss: 48616952.0000 - accuracy: 0.0000e+00 - val_loss: 7217069.5000 - val_accuracy: 0.1274\n","Epoch 5/50\n","19/19 [==============================] - 88s 5s/step - loss: 242602880.0000 - accuracy: 0.0000e+00 - val_loss: 32084140.0000 - val_accuracy: 0.0573\n","Epoch 6/50\n","19/19 [==============================] - 87s 5s/step - loss: 902079616.0000 - accuracy: 0.0000e+00 - val_loss: 111886992.0000 - val_accuracy: 0.0382\n","Epoch 7/50\n","19/19 [==============================] - 88s 5s/step - loss: 2863528704.0000 - accuracy: 0.1067 - val_loss: 328649632.0000 - val_accuracy: 0.0382\n","Epoch 8/50\n","19/19 [==============================] - 120s 7s/step - loss: 7647286784.0000 - accuracy: 0.1067 - val_loss: 837088192.0000 - val_accuracy: 0.0573\n","Epoch 9/50\n","19/19 [==============================] - 87s 5s/step - loss: 18277033984.0000 - accuracy: 0.2000 - val_loss: 1896778240.0000 - val_accuracy: 0.0573\n","Epoch 10/50\n"," 8/19 [===========>..................] - ETA: 21s - loss: 31340472320.0000 - accuracy: 0.0000e+00"]}],"source":["model.fit(train, batch_size=32, validation_data=test, epochs=50)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r8hnVpP8bDI7"},"outputs":[],"source":["model.save('bird_species_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8yw2VMkw2rwG"},"outputs":[],"source":["# Load the trained model\n","from tensorflow.keras.models import load_model\n","\n","model = load_model('/content/bird_species_model.h5')\n","\n","# Load the test dataset\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","test_data_dir = '/content/drive/MyDrive/AI_SmartInternz/archive/test_data/test_data'\n","test_gen = ImageDataGenerator(rescale=(1./255))\n","test = test_gen.flow_from_directory(test_data_dir,\n","                                    target_size=(120, 120),\n","                                    class_mode='categorical',\n","                                    batch_size=8)\n","\n","# Evaluate the model on the test dataset\n","test_loss, test_accuracy = model.evaluate(test)\n","\n","print(\"Test Loss:\", test_loss)\n","print(\"Test Accuracy:\", test_accuracy)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDMiF6A22sgS","executionInfo":{"status":"aborted","timestamp":1688367027555,"user_tz":-345,"elapsed":21,"user":{"displayName":"Ashutosh Shrestha","userId":"10288325656068295144"}}},"outputs":[],"source":["#Testing\n","import numpy as np\n","from tensorflow.keras.preprocessing import image\n","img = image.load_img('/content/Rebimg.jpeg',target_size=(120, 120))\n","model = load_model('/content/bird_species_model.h5')\n","img = image.img_to_array(img)\n","img=np.expand_dims(img,axis=0)\n","np.argmax(model.predict(img))\n","print(np.argmax(model.predict(img)))\n","#getting value from dict\n","indexKey=np.argmax(model.predict(img))\n","new_index_var[indexKey]"]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}